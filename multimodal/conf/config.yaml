# Common
random_seed: 42
lr: 0.0001

model_type: 'Pytorch'
model:
  _target_: models.HatefulMemesFusionModel
  text_hidden_dim: 768
  image_output_dim: 128
  fusion_output_dim: 256
  output_size: 2  # âœ… binary prediction so its two

dataset:
  name: 'hateful_memes'
  validation_split: 0.2

# Client
task_id: 'hatetaskthree'

wandb: 
  use: false
  key: 'your-wandb-key'
  account: 'your-wandb-account'
  project: '${dataset.name}_${task_id}'

# FL setup
num_epochs: 1
batch_size: 32
num_rounds: 2
clients_per_round: 2



server:
  strategy:
    _target_: aggregation.FedMAP.Map2FedAvgStrategy #my multimodal FL strategy
    fraction_fit: ${clients_per_round}
    fraction_evaluate: ${clients_per_round}
    min_fit_clients: ${clients_per_round}
    min_evaluate_clients: ${clients_per_round}
    min_available_clients: ${clients_per_round}
    # FedMAP hyperparams
    mlp_hidden: 16      # tune me(hideen dim of MLP) (this will be used to tune the MLP in serverside which will convert summary payload into modality embedding)
    meta_lr: 0.01       # tune me (learning rate of above MLP)
