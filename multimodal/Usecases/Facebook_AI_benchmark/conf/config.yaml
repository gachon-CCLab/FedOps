# Common
random_seed: 42
learning_rate: 0.0001   # lower LR is typical with BERT

model_type: 'Pytorch'
model:
  _target_: models.HatefulMemesFusionModel
  output_size: 2
  # optional knobs:
  # freeze_bert: false
  # pretrained_vision: true
  # bert_name: bert-base-uncased

dataset:
  name: 'HATEFUL_MEMES'
  validation_split: 0.0   # unused here but kept for API parity



# client
task_id: 'aqeelfacebook'

wandb:
  use: false
  key: 'your wandb api key'
  account: 'your wandb account'
  project: '${dataset.name}_${task_id}'

# server
num_epochs: 1
batch_size: 4           # multimodal batches are heavier than MNIST
num_rounds: 2
clients_per_round: 2

#############################################################################################################################################
##### ALL PARAMETERS BELOW ARE FEDMAP RELATED PARAMETERS###########################################################################
#############################################################################################################################################
# Yonggyeom, please do avoid this parameter in displaying in fedops task creation UI,as this is not needed for server side,but this is used only in client side
client_id: 0              # ‚Üê set to 0 for the first client; 1 for the second, etc.

# below are FedMAP related parameters,so display all this in Fedops task creation UI along with other config.yaml parameters
server:
  strategy:
    _target_:fedops.server.fedmap.strategy.ModalityAwareAggregation
    aggregator_path: "aggregator_mlp.pth"
    input_dim: 10
    hidden_dim: 16
    aggregator_lr: 0.001
    entropy_coeff: 0.01
    n_trials_per_round: 4      # Optuna trials cost real eval time here; consider fewer
    perf_mix_lambda: 0.7
    z_clip: 3.0
