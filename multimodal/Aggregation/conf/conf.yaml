# conf/config.yaml

# ── Common settings ──
random_seed: 42
lr: 0.0001

model_type: 'Pytorch'
model:
  _target_: models.HatefulMemesFusionModel
  text_hidden_dim: 768
  image_output_dim: 128
  fusion_output_dim: 256
  output_size: 2

dataset:
  name: 'hateful_memes'
  validation_split: 0.2

task_id: 'hatetaskthree'

wandb:
  use: false
  key: 'your-wandb-key'
  account: 'your-wandb-account'
  project: '${dataset.name}_${task_id}'

# ── FL hyperparameters ──
num_epochs: 1
batch_size: 32
num_rounds: 2
clients_per_round: 2

server:
  # build a shared dev‐set loader to pass into the strategy
  gl_val_loader:
    _target_: data_preparation.gl_model_torch_validation
    batch_size: ${batch_size}

  # swap in your Map²-FedAvg strategy
  strategy:
    _target_: strategies.Map2FedAvgStrategy # the newly introducing customized strategy
    dev_loader: ${server.gl_val_loader}   # Hydra will instantiate and inject this DataLoader
    mlp_hidden: 16                        # hidden size of the aggregator MLP
    meta_lr: 0.001                        # learning rate for the meta‐update step
    fraction_fit: 0.00001
    fraction_evaluate: 0.000001
    min_fit_clients: ${clients_per_round}
    min_available_clients: ${clients_per_round}
    min_evaluate_clients: ${clients_per_round}
